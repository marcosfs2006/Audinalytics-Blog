[
  {
    "path": "posts/2021-02-04-expresses-regulares-e-auditoria-ser-que-d-match/",
    "title": "Expressões Regulares e Auditoria: Será que dá _match_?",
    "description": "O objetivo desse *post* é apresentar possíveis situações em que o uso de expressões regulares pode ser útil em trabalhos de auditoria e com isso estimular os auditores a conhecer um pouquinho mais sobre esse recurso.",
    "author": [
      {
        "name": "Marcos F. Silva",
        "url": {}
      }
    ],
    "date": "2021-02-07",
    "categories": [],
    "contents": "\r\nDuas situações para motivação…\r\nImagine que você está realizando uma auditoria e que após executar alguns testes baseados na Lei de Benford você tenha descoberto que os valores que iniciam pelos caracteres “50”1 tenham fugido muito ao que seria o esperado.\r\n\r\nA Lei de Benford é uma técnica de análise de dados bastante popular em auditoria para a detecção de não conformidades em valores numéricos e integra as denominadas Técnicas de Auditoria Assistidas por Computador - TAACs\r\nPara uma análise mais detalhada das não conformidades identificadas você resolve filtrar a base de dados para obter apenas os registros em que os valores da variável objeto de análise inicie com a string “50”. Expressões regulares podem ser utilizadas para auxiliar na realização desse filtro.\r\nUma outra situação em que conhecer expressões regulares pode ser bastante útil é realizar filtragem de bases de dados com base em variáveis cujos valores sejam texto. Um exemplo disso seria uma base de dados composta por notas de empenhos e se deseja filtrar os dados com base na variável que contenha a descrição da despesa para identificar os empenhos que tenham relação, por exemplo, com “COVID-19”.\r\nEssas são duas situações particulares de um caso mais geral que é aplicar filtros a uma base de dados utilizando expressões regulares.\r\nNa prática o uso de expressões regulares é muito mais amplo e auxilia bastante no processo de pré-processamento das bases de dados.\r\nMas acredito que a essa altura você deva estar se perguntando: “Legal, mas pra mim isso tá parecendo com o recurso de localizar existente no Word. Qual a vantagem de aprender isso?”\r\nDiferentemente do recurso de localizar, onde o “match” só ocorre se as strings coincidirem de forma exata, as expressões regulares são muito mais flexíveis para a definição de padrões que descrevam as strings desejadas e isso pode economizar muito tempo, em razão do auditor não precisar testar várias strings semelhantes.\r\n\r\nDiz-se que ocorreu um match quando o padrão de string expresso pela expressão regular coincide com um subconjunto das strings objeto de pesquisa. Isso ficará mais claro adiante.\r\nMas o que é uma expressão regular?\r\nDe acordo com o tutorial contido no pacote stringr, expressões regulares são ferramentas para a descrição de padrões em strings de caracteres de forma concisa e flexível.\r\nNão é minha intenção que este post seja um tutorial sobre expressões regulares, mas chamar a atenção dos auditores para esse recurso, mostrar possibilidades de aplicações e com isso estimular um aprofundamento dos conhecimentos. E para isso elenco mais adiante alguns recursos disponíveis na internet.\r\nVou usar inicialmente alguns exemplos muito simples para fins didáticos e depois faço aplicações em um conjunto de dados mais realista.\r\nUso funções do pacote stringr para demonstrar o uso das expressões regulares e aproveito para chamar a atenção dos auditores para o fato de que manipular valores textuais é uma habilidade que pode ser muito útil.\r\nConsidere o seguinte conjunto de strings:\r\n\r\n\r\nlibrary(stringr)\r\nlibrary(readr)\r\n\r\nnomes<- c(\"Marcolino\", \"Marcos\", \"José\", \"joão\", \"Marcio\")\r\nnomes\r\n\r\n\r\n[1] \"Marcolino\" \"Marcos\"    \"José\"      \"joão\"      \"Marcio\"   \r\n\r\nVamos agora supor que eu queira identificar nesse conjunto de strings (cada nome é uma string) aquelas que comecem com a letra jota maiúscula ou minúscula. Como deve ser a expressão regular que ‘casa’ com esse padrão?\r\nA função str_view() do pacote stringr permite verificar para quais strings houve um “match” com o padrão definido pela expressão regular. No exemplo, o padrão é: “string que inicia com a letra jota”.\r\n\r\n\r\nstr_view(string=nomes, pattern=\"^[Jj]\")\r\n\r\n\r\npreserve8fbe78d0584023da\r\n\r\nComo é possível ver pelo resultado, as strings José e joão ‘casaram’ com a expressão regular ^[Jj] que define o padrão desejado, ou seja, iniciam com a letra jota, seja ela maiúscula ou minúscula.\r\nA definição de expressões regulares faz uso de caracteres que possuem significado especial os quais são denominados de metacaracteres. Os metacaracteres ^ e [] tem funções bem específicas.\r\nA indicação de que a letra jota deve estar no ínício da string é dada pelo matacaractere ^, enquanto a indicação que o jota poderia ser maiúsculo ou minúsculo é dada pelo matacaractere [] que, no exemplo, informa que a string pode iniciar com qualquer dos caracteres em seu interior.\r\nE se quisermos identificar as strings que terminem com “o” ou “os”?\r\n\r\n\r\nstr_view(string=nomes, pattern=\"os?$\")\r\n\r\n\r\npreserve18beeb72e9a74827\r\n\r\nEsse exemplo, embora ainda simples, já começa a indicar que as expressões regulares podem ser bem complexas. E de fato são.\r\nNesse exemplo, aparecem mais dois novos metacaracteres: $ e ?. O metacaractere $ é responsável por indicar que os caracteres desejados devem estar no final da string enquanto o metacaractere ? informa que o caractere que o precede é opcional, podendo aparecer ou não na string. Assim, essa expressão regular define o seguinte padrão: strings que terminem com o caractere o sucedido ou não do caractere s.\r\n\r\n\r\nstr_view(string=nomes, pattern=\"[nc]os?$\")\r\n\r\n\r\npreserve533b5dda7319eb8d\r\n\r\nNo exemplo acima, a expressão regular define o seguinte padrão: o caractere o precedido dos caracteres n ou c e sucedido ou não do caractere s no final da string.\r\nNaturalmente que existem muitos outros metacaracteres que não foram abordados nesses exemplos simples cujo objetivo é apenas passar a ideia do que sejam expressões regulares.\r\nConvido o leitor a consultar as referências elencadas mais adiante para um tratamento mais aprofundado do assunto.\r\nAgora vou usar um conjunto de dados um pouco mais realista. Trata-se de uma relação de empenhos obtida no portal da transparência do Tribunal de Contas do Estado da Paraíba.\r\n\r\nA relação de empenhos refere-se apenas à Secretaria Estado de Educação e compreende os meses de janeiro a dezembro de 2020.\r\n\r\n\r\nempenhos <- read_csv(\"C:\\\\Users\\\\Marcos\\\\OneDrive\\\\Marcos\\\\audinalytics-dados\\\\EmpenhosLista.csv\")\r\nhead(empenhos)\r\n\r\n\r\n# A tibble: 6 x 9\r\n  DT_EMPENHO DS_TIPO NumNE CD_ORGAO ElementoDespesa DS_CREDOR\r\n  <chr>      <chr>   <chr> <chr>    <chr>           <chr>    \r\n1 23/01/2020 PRINCI~ 2020~ VALOR D~ 11-VENCIMENTOS~ 08.778.2~\r\n2 23/01/2020 PRINCI~ 2020~ VALOR D~ 11-VENCIMENTOS~ 08.778.2~\r\n3 23/01/2020 PRINCI~ 2020~ VALOR D~ 11-VENCIMENTOS~ 08.778.2~\r\n4 23/01/2020 PRINCI~ 2020~ VALOR D~ 05-OUTROS BENE~ 08.778.2~\r\n5 23/01/2020 PRINCI~ 2020~ VALOR D~ 11-VENCIMENTOS~ 08.778.2~\r\n6 23/01/2020 PRINCI~ 2020~ VALOR D~ 11-VENCIMENTOS~ 08.778.2~\r\n# ... with 3 more variables: Valor_Despesa1 <chr>, Textbox7 <chr>,\r\n#   Valor_Despesa <chr>\r\n\r\nDurante o processo de exportação dos dados do site, algumas colunas indesejadas foram exportadas também, são elas: Textbox7 e Valor_Despesa. Vou eliminar essas colunas da base de dados:\r\n\r\n\r\nlibrary(dplyr)\r\nempenhos <- empenhos %>% \r\n              select(-Textbox7, -Valor_Despesa)\r\n\r\nglimpse(empenhos)\r\n\r\n\r\nRows: 6,781\r\nColumns: 7\r\n$ DT_EMPENHO      <chr> \"23/01/2020\", \"23/01/2020\", \"23/01/2020\",...\r\n$ DS_TIPO         <chr> \"PRINCIPAL\", \"PRINCIPAL\", \"PRINCIPAL\", \"P...\r\n$ NumNE           <chr> \"2020NE00001\", \"2020NE00002\", \"2020NE0000...\r\n$ CD_ORGAO        <chr> \"VALOR DA FOLHA DE PESSOAL - DEMAIS DA ED...\r\n$ ElementoDespesa <chr> \"11-VENCIMENTOS E VANTAGENS FIXAS - PESSO...\r\n$ DS_CREDOR       <chr> \"08.778.250/0001-69 - SECRETARIA DE ESTAD...\r\n$ Valor_Despesa1  <chr> \"4.999.161,91\", \"2.388,72\", \"103.288,98\",...\r\n\r\nA variável Valor_Despesa1 foi importada como caractere em vez de número. Com o uso de expressões regulares é possível fazer o pré-processamento com vistas à conversão para o formato numérico.\r\nVárias funções no R recebem como argumentos expressões regulares. No código a seguir vou utilizar a função str_replace_all() do pacote stringr para realizar a conversão da variável Valor_Despesa1 para o formato numérico.\r\nEssa função recebe como argumentos a variável contendo as strings, a expressão regular definindo o padrão a ser ‘casado’ e a string a ser utilizada para substituir a string que deu match com o padrão especificado.\r\nPara que a conversão possa ocorrer será necessário: (1) “remover” os pontos e (2) “substituir” as vírgulas por pontos.\r\nNo código a seguir eu utilizo a expressão regular \\\\. para ‘casar’ os pontos e substituir por uma string nula.\r\n\r\n\r\nempenhos <- empenhos %>% \r\n              mutate(Valor_Despesa1 = str_replace_all(Valor_Despesa1, \"\\\\.\", \"\"))\r\nglimpse(empenhos)\r\n\r\n\r\nRows: 6,781\r\nColumns: 7\r\n$ DT_EMPENHO      <chr> \"23/01/2020\", \"23/01/2020\", \"23/01/2020\",...\r\n$ DS_TIPO         <chr> \"PRINCIPAL\", \"PRINCIPAL\", \"PRINCIPAL\", \"P...\r\n$ NumNE           <chr> \"2020NE00001\", \"2020NE00002\", \"2020NE0000...\r\n$ CD_ORGAO        <chr> \"VALOR DA FOLHA DE PESSOAL - DEMAIS DA ED...\r\n$ ElementoDespesa <chr> \"11-VENCIMENTOS E VANTAGENS FIXAS - PESSO...\r\n$ DS_CREDOR       <chr> \"08.778.250/0001-69 - SECRETARIA DE ESTAD...\r\n$ Valor_Despesa1  <chr> \"4999161,91\", \"2388,72\", \"103288,98\", \"14...\r\n\r\nComo pode ser visto, os pontos foram removidos. A expressão regular \\\\. ‘casa’ os pontos. Como o ponto tem um significado especial em expressões regulares, para que seja possível casar o ‘ponto literal’ é necessário colocar as duas barras antes dele. Em expressões regulares, o ponto tem a função de ‘casar’ com qualquer caractere.\r\nAgora é necessário substituir a vírgula por ponto.\r\n\r\n\r\nempenhos <- empenhos %>% \r\n              mutate(Valor_Despesa1 = str_replace_all(Valor_Despesa1, \",\", \".\"))\r\nglimpse(empenhos)\r\n\r\n\r\nRows: 6,781\r\nColumns: 7\r\n$ DT_EMPENHO      <chr> \"23/01/2020\", \"23/01/2020\", \"23/01/2020\",...\r\n$ DS_TIPO         <chr> \"PRINCIPAL\", \"PRINCIPAL\", \"PRINCIPAL\", \"P...\r\n$ NumNE           <chr> \"2020NE00001\", \"2020NE00002\", \"2020NE0000...\r\n$ CD_ORGAO        <chr> \"VALOR DA FOLHA DE PESSOAL - DEMAIS DA ED...\r\n$ ElementoDespesa <chr> \"11-VENCIMENTOS E VANTAGENS FIXAS - PESSO...\r\n$ DS_CREDOR       <chr> \"08.778.250/0001-69 - SECRETARIA DE ESTAD...\r\n$ Valor_Despesa1  <chr> \"4999161.91\", \"2388.72\", \"103288.98\", \"14...\r\n\r\nAs vírgulas foram substituídas por pontos. Agora é só converter a variável para o formato numérico.\r\n\r\n\r\nempenhos <- empenhos %>% \r\n              mutate(Valor_Despesa1 = as.numeric(Valor_Despesa1))\r\nglimpse(empenhos)\r\n\r\n\r\nRows: 6,781\r\nColumns: 7\r\n$ DT_EMPENHO      <chr> \"23/01/2020\", \"23/01/2020\", \"23/01/2020\",...\r\n$ DS_TIPO         <chr> \"PRINCIPAL\", \"PRINCIPAL\", \"PRINCIPAL\", \"P...\r\n$ NumNE           <chr> \"2020NE00001\", \"2020NE00002\", \"2020NE0000...\r\n$ CD_ORGAO        <chr> \"VALOR DA FOLHA DE PESSOAL - DEMAIS DA ED...\r\n$ ElementoDespesa <chr> \"11-VENCIMENTOS E VANTAGENS FIXAS - PESSO...\r\n$ DS_CREDOR       <chr> \"08.778.250/0001-69 - SECRETARIA DE ESTAD...\r\n$ Valor_Despesa1  <dbl> 4999161.91, 2388.72, 103288.98, 14245.66,...\r\n\r\nAgora variável Valor_Despesa1 está no formato numérico.\r\nContinuando com nosso exemplo, vamos supor que eu queira filtrar a base de dados de forma que apenas os valores dos empenhos iniciados por “50” sejam selecionados. Usando a expressão regular já vista anteriormente posso fazer isso da seguinte forma:\r\n\r\n\r\nempenhos_50 <- empenhos %>% \r\n                  filter(str_detect(Valor_Despesa1, \"^50\"))\r\nknitr::kable(head(empenhos_50))\r\n\r\n\r\nDT_EMPENHO\r\nDS_TIPO\r\nNumNE\r\nCD_ORGAO\r\nElementoDespesa\r\nDS_CREDOR\r\nValor_Despesa1\r\n12/02/2020\r\nPRINCIPAL\r\n2020NE00253\r\nIMPORTANCIA EMPENHADA PARA A REALIZACAO DA DESPESA COM PAGAMENTO DE DIARIA CONFORME MAPA DE CONCESSAO EM ANEXO\r\n14-DIÁRIAS - CIVIL\r\n*.807.644- - JOSE PATRICIO DA SILVA\r\n50\r\n12/02/2020\r\nPRINCIPAL\r\n2020NE00254\r\nIMPORTANCIA EMPENHADA PARA A REALIZACAO DA DESPESA COM PAGAMENTO DE DIARIA CONFORME MAPA DE CONCESSAO EM ANEXO\r\n14-DIÁRIAS - CIVIL\r\n*.807.644- - JOSE PATRICIO DA SILVA\r\n50\r\n12/02/2020\r\nPRINCIPAL\r\n2020NE00257\r\nIMPORTANCIA EMPENHADA PARA A REALIZACAO DA DESPESA COM PAGAMENTO DE DIARIA CONFORME MAPA DE CONCESSAO EM ANEXO\r\n14-DIÁRIAS - CIVIL\r\n*.421.508- - TIAGO FRANCISO DE SOUSA DA SILVA\r\n50\r\n12/02/2020\r\nPRINCIPAL\r\n2020NE00258\r\nIMPORTANCIA EMPENHADA PARA A REALIZACAO DA DESPESA COM PAGAMENTO DE DIARIA CONFORME MAPA DE CONCESSAO EM ANEXO\r\n14-DIÁRIAS - CIVIL\r\n*.421.508- - TIAGO FRANCISO DE SOUSA DA SILVA\r\n50\r\n13/02/2020\r\nPRINCIPAL\r\n2020NE00261\r\nIMPORTANCIA EMPENHADA PARA A REALIZACAO DA DESPESA COM PAGAMENTO DE DIARIA CONFORME MAPA DE CONCESSAO EM ANEXO\r\n14-DIÁRIAS - CIVIL\r\n*.421.508- - TIAGO FRANCISO DE SOUSA DA SILVA\r\n50\r\n13/02/2020\r\nPRINCIPAL\r\n2020NE00262\r\nIMPORTANCIA EMPENHADA PARA A REALIZACAO DA DESPESA COM PAGAMENTO DE DIARIA CONFORME MAPA DE CONCESSAO EM ANEXO\r\n14-DIÁRIAS - CIVIL\r\n*.421.508- - TIAGO FRANCISO DE SOUSA DA SILVA\r\n50\r\n\r\nMais um exemplo. A variável DS_CREDOR possui a identificação do credor do empenho. Essa identificação consiste do número do CNPJ seguido do nome do fornecedor caso esse seja pessoa jurídica. No caso de pessoa física, essa descrição consiste de parte do CPF seguido do nome da pessoa.\r\nVamos supor que eu queira criar um novo campo na base de dados contendo apenas o CNPJ. Como eu posso fazer isso usando expressões regulares? Eu preciso criar uma expressão regular que defina o padrão de um CNPJ, que é: dois dígitos, ponto, três digitos, ponto, três dígitos, barra, três zeros, um, hífen, dois dígitos. Como eu crio uma expressão regular que “case” com esse padrão?\r\nUma possibilidade:\r\n\r\n\r\npadrao_cnpj <- \"\\\\d{2}\\\\.\\\\d{3}\\\\.\\\\d{3}/0001-\\\\d{2}\"\r\n\r\n\r\n\r\nExplicando um pouco. O metacaractere \\\\d{n} indica que o padrão buscado é n dígitos. O \\\\. indica que queremos ‘casar’ o ponto. Como o ponto possui um significado especial nas expressões regulares (é um metacaractere), é necessário precedê-lo com as duas barras.\r\nVamos agora criar a nova coluna.\r\n\r\n\r\nempenhos <- empenhos %>% \r\n              mutate(CNPJ_CREDOR = str_extract(DS_CREDOR, padrao_cnpj))\r\nglimpse(empenhos)\r\n\r\n\r\nRows: 6,781\r\nColumns: 8\r\n$ DT_EMPENHO      <chr> \"23/01/2020\", \"23/01/2020\", \"23/01/2020\",...\r\n$ DS_TIPO         <chr> \"PRINCIPAL\", \"PRINCIPAL\", \"PRINCIPAL\", \"P...\r\n$ NumNE           <chr> \"2020NE00001\", \"2020NE00002\", \"2020NE0000...\r\n$ CD_ORGAO        <chr> \"VALOR DA FOLHA DE PESSOAL - DEMAIS DA ED...\r\n$ ElementoDespesa <chr> \"11-VENCIMENTOS E VANTAGENS FIXAS - PESSO...\r\n$ DS_CREDOR       <chr> \"08.778.250/0001-69 - SECRETARIA DE ESTAD...\r\n$ Valor_Despesa1  <dbl> 4999161.91, 2388.72, 103288.98, 14245.66,...\r\n$ CNPJ_CREDOR     <chr> \"08.778.250/0001-69\", \"08.778.250/0001-69...\r\n\r\nA nova coluna foi criada apenas com o CNPJ como desejado. Mas vamos supor ainda que eu queira cruzar esta base de dados com uma outra tomando o CNPJ como chave para o cruzamento. Ocorre que nessa outra base o CNPJ está sem pontuação, ou seja, os CNPJ aparecem dessa forma: “08778250000169”. Assim eu preciso remover a pontuação na variável recém criada. Mais uma vez vou utilizar expressão regular.\r\n\r\n\r\nempenhos <- empenhos %>% \r\n              mutate(CNPJ_CREDOR = str_remove_all(CNPJ_CREDOR, \"[[:punct:]]\"))\r\nglimpse(empenhos)\r\n\r\n\r\nRows: 6,781\r\nColumns: 8\r\n$ DT_EMPENHO      <chr> \"23/01/2020\", \"23/01/2020\", \"23/01/2020\",...\r\n$ DS_TIPO         <chr> \"PRINCIPAL\", \"PRINCIPAL\", \"PRINCIPAL\", \"P...\r\n$ NumNE           <chr> \"2020NE00001\", \"2020NE00002\", \"2020NE0000...\r\n$ CD_ORGAO        <chr> \"VALOR DA FOLHA DE PESSOAL - DEMAIS DA ED...\r\n$ ElementoDespesa <chr> \"11-VENCIMENTOS E VANTAGENS FIXAS - PESSO...\r\n$ DS_CREDOR       <chr> \"08.778.250/0001-69 - SECRETARIA DE ESTAD...\r\n$ Valor_Despesa1  <dbl> 4999161.91, 2388.72, 103288.98, 14245.66,...\r\n$ CNPJ_CREDOR     <chr> \"08778250000169\", \"08778250000169\", \"0877...\r\n\r\nA expressão regular [[:punct:]] “casa” com os sinais de pontuação.\r\nMais um exemplo para finalizar. A variável CD_ORGAO contém a descrição da despesa objeto do empenho. Como poderíamos identificar os empenhos que se refiram a compra de merenda escolar, por exemplo?\r\nNo código a seguir vou usar expressão regular para “casar” a string MERENDA na descrição da despesa.\r\n\r\n\r\nempenhos_merenda <- empenhos %>% \r\n                      filter(str_detect(CD_ORGAO, \"MERENDA\")) \r\n\r\n\r\n\r\nO novo conjunto de dados empenhos_merenda contém apenas os registros referentes aos empenhos em que a string MERENDA aparece na descrição da despesa.\r\nEspero que estes exemplos tenham dado uma ideia do poder que as expressões regulares trazem para a análise de dados e, consequentemente, para a auditoria e que o post de modo geral tenha aguçado sua curiosidade para aprender mais sobre esta ferramenta fantástica.\r\nOnde aprofundar os conhecimentos\r\nCom uma rápida pesquisa na internet é possível encontrar uma grande quantidade de material sobre expressões regulares.\r\nListo a seguir alguns materiais que vão te ajudar a aprofundar o conhecimento sobre esse tópico.\r\nIntrodução ao regex com R\r\nBasic Regular Expressions in R - Cheat Sheet\r\nR for Data Science - Capítulo 14 Strings\r\nRegular expressions\r\nRegular Expressions in R - Albert Y. Kim\r\n\r\nNesse post vou adotar a seguinte terminologia: um caractere pode ser qualquer dígito, letra, pontuação, etc e uma string será um conjunto de caracteres. Assim, “@marcos2006”, “123456” e “Apt. 708” são strings↩︎\r\n",
    "preview": {},
    "last_modified": "2021-02-07T21:07:47-03:00",
    "input_file": "expresses-regulares-e-auditoria-ser-que-d-match.utf8.md"
  },
  {
    "path": "posts/2021-01-27-audit-analytics/",
    "title": "Audit Analytics",
    "description": "Neste _post_ meu objetivo é falar um pouco sobre o que é _Audit Analytics_ e onde encontrar material para estudo.",
    "author": [
      {
        "name": "Marcos F. Silva",
        "url": {}
      }
    ],
    "date": "2021-01-31",
    "categories": [],
    "contents": "\r\n\r\nContents\r\nO que é Audit Analytics?\r\nA Análise de Dados Aplicada à Auditoria Hoje\r\nVantagens da Audit Analytics\r\nMaterial para Estudo\r\n\r\nO que é Audit Analytics?\r\nO uso de análise de dados ou métodos quantitativos ou machine learning em auditoria tem sido apresentado com a denominação de Audit Analytics ou Audit Data Analytics e um breve resumo e introdução a esta ‘disciplina’ pode ser consultado neste documento produzido pela Escola de Negócios da Universidade de Rutgers em 2013.\r\nO documento inicia declarando que “Audit analytics é o uso da tecnologia de análise de dados em Auditoria”. Depois, complementa informando que “Audit analytics é o processo de identificar, colher, validar, analisar e interpretar várias formas de dados dentro de uma organização para ajudar no desenvolvimento do propósito e missão da auditoria.”\r\nTambém é interessante elencar as possíveis aplicações da Audit Analytics no processo de auditoria, ainda segundo o documento em referência:\r\nRevisão analítica;\r\nAvaliação e testes de controles;\r\nTestes substantivos;\r\nDetecção de fraudes;\r\nAnálises em geral e produção de relatórios;\r\nTransações financeiras e não financeiras.\r\nO Guide to Audit Data Analytics da AICPA apresenta uma ‘definição’ de Audit Data Analytics (ADA) da qual gosto muito e que está no artigo Reimagining Auditing in a Wired World de autoria de Paul Byrnes e outros .\r\nDe acordo com os autores do artigo Audit Data Analytics é “a ciência e a arte de descobrir e analisar padrões, identificar anomalias e extrair outras informações úteis de dados subjacentes ou relacionados a um objeto de auditoria através de análise, modelagem ou visualização com o objetivo de planejar ou realizar a auditoria.”\r\nAinda de acordo com o Guia, a ADA “são técnicas que que podem ser usadas para realizar vários procedimentos de auditoria incluindo elementos de avaliação de risco, testes de controles, procedimentos substantivos (isto é, testes de detalhes ou procedimentos analíticos substantivos),ou procedimentos de fechamento de auditoria. ADAs e procedimentos analíticos estão interrelacionados mas nem todas as ADAs são procedimentos analíticos.”\r\nAs definições acima remetem a algumas ideias que me parecem centrais para o entendimento do que seja Audit Analytics.\r\nNo documento da Rutgers essas ideias aparecem bem explícitas na definição, que é o uso de tecnologia, para realizar análise de dados na área de auditoria.\r\nNa definição contida no artigo de Byrnes et all, aparecem as ideias de “descobrir e analisar padrões”, “identificar anomalias”, “extrair outras informações úteis de dados”, “através de análise, modelagem ou visualização” que estão associadas a análise de dados e, como decorrência, a todo o conhecimento técnico relacionado a essa área do conhecimento.\r\nOs dados objeto de análise são aqueles “subjacentes ou relacionados a um objeto de auditoria” com o objetivo de “planejar ou realizar a auditoria”, que fala da área de conhecimento na qual a análise de dados será aplicada, a auditoria. Também aqui, existe um corpo de conhecimento específico com o qual os profissionais oriundos das ciências contábeis estão mais familiarizados.\r\nNessa definição não há menção a nada que remeta à tecnologia. Mas me parece claro que essa omissão talvez tenha relação com o fato de que as tecnologias são passageiras, a todo momento estão surgindo novas e melhores ferramentas capazes de realizar a análise dos dados de forma satisfatória.\r\nA definição do Guia da AICPA faz alusão ao conceito de análise de dados ao associar a Audit Analytic a um conjunto de técnicas e enfatiza bastante a área de aplicação, ao detalhar onde na auditoria podem ser utilizadas.\r\nTambém aqui não há menção à tecnologia. O foco da definição está nas áreas de aplicação e faz todo o sentido que assim seja, visto que o objetivo do Guia é, declaradamente, “fornecer uma introdução e visão geral às técnicas de análise de dados para auxiliar os auditores de demonstrações financeiras na aplicação dessas técnicas durante realização de uma auditoria”.\r\nComo pode ser visto, o Guia da AICPA é direcionado a auditores, auditores de demonstrações financeiras, os quais usualmente são contadores cuja formação, ao menos aqui no Brasil, é deficiente em análise de dados e uso de tecnologia. Não é incomum que os livros texto nacionais de auditoria ainda ensinem a executar testes de auditoria utilizando papel colunado!\r\nPara esse público, o interesse está em saber como essas técnicas podem ser incorporadas em seu trabalho, quais são as vantagens, quais são os custos de adoção e desvantagens.\r\nNesse site, o meu foco será a implementação prática das técnicas de análise de dados em auditoria, utilizando como tecnologia o ambiente R. Não é meu objetivo discutir conceitos de auditoria financeira ou de qualquer outro tipo de auditoria. Para quem quiser conhecer esses conceitos recomento o Manual de Auditoria Financeira do TCU.\r\nUma questão que pode surgir é: que técnicas de análise de dados são essas?\r\nElas variam desde as técnicas mais básicas então conhecidas por Técnicas de Auditoria Assistidas por Computador - TAACs até as modernas técnicas de mineração de dados passando por visualização de dados.\r\nSem a pretensão de ser exaustivo, elenco a seguir algumas técnicas citadas na literatura como utilizadas em trabalhos de auditoria:\r\nTécnicas de Auditoria Assistidas por Computador - TAACs: estatistica descritiva, distribuição de frequencias e tabulação cruzada, sumarização, estratificação, análise de tendências, Aging, teste de duplicidade e gaps, lei de Benford, amostragem de auditoria, etc.\r\nVisualização de Dados:histograma, diagrama de dispersão, gráfico de linhas, gráfico de barras (simples, empilhados e justapostos), boxplot, etc.\r\nTécnicas Preditivas (aprendizado supervisionado): regressão (simples, múltipla, logística), árvores de decisão, máquinas de vetor suporte, etc.\r\nTécnicas Descritivas/Exploratórias (aprendizado não supervisionado): regras de associação, análise de cluster, análise de componentes principais, análise de redes sociais, mineração de texto, mineração de processos, etc.\r\n* etc.\r\nA Análise de Dados Aplicada à Auditoria Hoje\r\nNa introdução do livro Audit Analytics in the Financial Industry Jun Dai e Miklos Vasarhelyi colocam a seguinte questão: O que é Audit Analytics?\r\nEste livro é uma coletânea de artigos editada por Jun Dai, Miklos A. Vasarhelyi e Ann F. Medinets, publicado em 2019.\r\nOs autores observam que a tecnologia emergente da Audit Analytics (AA) vem sendo cada vez mais utilizada pelos auditores para extrair e processar dados oriundos de uma variedade de fontes para identificação de risco, coleta de evidências e, em última análise, dar suporte à tomada de decisão.\r\nAtualmente estão acessíveis aos auditores além dos dados oriundos dos sistemas contábeis dos clientes, dados públicos como os disponibilizados nas mídias sociais e na internet de modo geral, dados abertos governamentais, dados climáticos e dados oriundos da ‘internet das coisas’ (IoT).\r\nO auditor moderno não pode, e não deve, ficar limitado aos dados internos produzidos pela entidade auditada.\r\nOs autores chamam a atenção para o seguinte fato: “Os procedimentos analíticos tradicionais se baseiam fortemente em amostragens dos dados relacionados à auditoria. Não obstante, à medida que os sistemas de ERP estão rapidamente crescendo em popularidade entre as empresas, evidência suficiente não pode mais ser colhida apenas de uma amostra de dados. A Audit Analytics aumenta a população testada de amostras limitadas (subjetiva ou estatística) para milhões de transações na testagem de toda a população o que amplia a cobertura da auditoria de um pequeno percentual das transações para toda a população.”\r\nOs autores vêem a Audit Analytics como sucessora dos procedimentos analíticos que já a bastante tempo vem sendo utilizados pelos auditores externos como técnica para o planejamento, testes substantivos e fase de conclusão de auditoria.\r\nConsiderando que os procedimentos analíticos realizados na fase de planejamento da auditoria tipicamente usam dados agregados em alto nível os resultados obtidos com estes procedimentos fornecem apenas indicação geral inicial sobre a existência de erros materiais.\r\nPor outro lado as técnicas de AA podem ser utilizadas em dados ao nível de transações visto que estas técnicas mantém boa performance ainda quando utilizadas em grandes bases de dados e bases com alta dimensionaliade.\r\nComo resultado a AA pode aumentar a acurácia da avaliação de riscos e melhorar a qualidade do planejamento da auditoria.\r\nEm um artigo de 2003 chamado Audit at a Crossroads, Conan C. Albrech, em vista dos então recentes escândalos de fraude ocorridos em empresas como Enron, WorldCom, Homestore, Quest, Global Crossing, Adelphia, Xerox, Waste Management, Sunbeam e outras, que colocaram a atividade de auditoria independente em xeque e do claro gap de expectativa existente entre o que os auditores afirmam ser sua responsabilidade e o que os usuários das informações contábeis acreditam ser o produto de seu trabalho, já chamava a atenção para a necessidade de uma revisão no modelo de auditoria com vistas a focar na fraude de demostrações financeiras, propondo duas grandes modificações: análise de toda a população e detecção de fraude pró-ativa.\r\nNa visão do autor, existe uma necessidade de que métodos estatísticos e tecnológicos sejam inseridos no processo de auditoria com vistas a focar nas fraudes de demonstrações financeiras e para isso propõe as duas modificações acima elencadas.\r\nEssa proposição assenta no entendimento do autor de que “a disponibilidade de tecnologia e dados em formato digital torna possível realizar rotinas de mineração de dados de formas que historicamente tem sido muito custosa ou mesmo impossível.”\r\nDestaco que a aplicação de técnicas de mineração de dados na detecção de fraudes tem sido tão bem sucedida que uma disciplina própria chamada Fraud Analytics vem se desenvolvendo e ganhando cada vez mais espaço.\r\nVantagens da Audit Analytics\r\nVoltando ao artigo de Jun Dai e Miklos Vasarhelyi, as tecnologias emergentes de análise de dados possuem a capacidade de explorar vastas quantidades de dados em várias estruturas e formatos que não podem ser manipulados pelos procedimentos analíticos tradicionais.\r\nComo vantagens da AA sobre as técnicas mais tradicionais os autories citam: (1) audit data analytics tem um melhor custo benefício em termos de coleta de evidências, (2) muitas das técnicas de análise de dados são escaláveis, isto é, em geral ainda mantém boa performance quando trabalham com grandes quantidades de dados com alta dimensionalidade (muitas variáveis) e (3) algumas técnicas de AA também possuem a habilidade de identificar padrões nos dados com o uso de técnicas não supervisionadas, o que dispensa a necessidade de dados ‘rotulados’ (variáveis alvo) no conjunto de dados.\r\nMaterial para Estudo\r\nInfelizmente não há muito material de estudo em português sobre o tema Audit Data Analytics, mas em inglês já é possível encontrar alguns materiais interessantes.\r\nLivros\r\nAinda são poucos os livros dedicados ao assunto. Listo a seguir os que conheço:\r\nAudit Analytics in the Financial Industry\r\nAudit Analytics and Continuous Audit - Looking Toward the Future Coletânea de artigos disponível para download.\r\nGuide to Audit Data Analytics\r\nAudit Analytics - Data Science for the Accounting Profession\r\nBasic Audit Data Analytics with R\r\nData analytics for internal auditors\r\nData Analytics: Elevating Internal Audit’s Value\r\nTeses e Dissertações\r\nA universidade de Rutgers é um forte centro de pesquisa no uso das modernas técnicas de mineração de dados em auditoria financeira e ao longo dos últimos anos diversas teses de doutoramento foram produzidas abordando a aplicação de análise de dados em auditoria.\r\nListo abaixo algumas das teses que tratam da temática Análise de Dados em Auditoria as quais estão disponíveis para download e podem ser obtidas no seguinte link: https://rucore.libraries.rutgers.edu/\r\nTitulo\r\nAutor\r\nAno de Produção\r\nCluster Analysis for Anomaly Detection in Accounting\r\nSutapat Thiprungsri\r\nJan. 2011\r\nPredictive Audit Analytics: Evolving to a New Era\r\nSiripan Kuenkaikaew\r\nOut. 2013\r\nThe Application of Exploratory Data Analytis in Auditing\r\nQi Liu\r\nOut. 2014\r\nThe Application of Data Visualization in Auditing\r\nAbdullah Alawaddhi\r\nMai. 2015\r\nDeveloping Automated Applications for Clustering and Outlier Detection: Data Mining Implications for Auditing Practice\r\nPaul Eric Byrnes\r\nOut 2015\r\nAnalytics with Exception Prioritization, Consumer Search Volume, and Social Capital\r\nPei Li\r\nMai. 2016\r\nAuditing in Environments of Diverse Data\r\nBasma Moharram\r\nOut. 2016\r\nThree Essays on Audit Technology: Audit 4.0, blockchain, and Audit App\r\nJun Dai\r\nOut. 2017\r\nPublic Auditing, Analytics, and Big Data in the Modern Economy\r\nDeniz Appelbaum\r\nMai., 2017\r\nDesigning Continuous Audit Analytics and Fraud Prevention Systems Using Emerging Technologies\r\nYunsen Wang\r\nMai. 2018\r\nExploring New Audit Evidence: The Application of Process Mining in Auditing\r\nTiffany Chiu\r\nMai. 2018\r\nDeep Learning Applications in Audit Decision Making\r\nTing Sun\r\nMai. 2018\r\nThree Essays on Emerging Technologies in Accounting\r\nFeiqi Huang\r\nJan. 2019\r\nThree Essays on Audit Innovation: Using Social Media Information and Disruptive Technologies to Enhance Audit Quality\r\nAndrea M. Rozario\r\nMai. 2019\r\nApplying Textual Analysis to Auditing\r\nYue Liu\r\nMai. 2019\r\nThree Essays on Open Government Data and Data Analytics\r\nZamil S. Alzamil\r\nMai. 2019\r\nAudit Focused Process Mining: The Evolution of Process Mining and Internal Control\r\nAbddulrahman Alrefai\r\nMai. 2019\r\nThree Essays on the Adoption and Application of Emerging Technologies in Accounting\r\nZhaokai Yan\r\nOut. 2019\r\nArtigos\r\nTembem vale a pena dar uma conferida nos seguintes artigos disponíveis online:\r\nEmbracing the automated audit\r\nThe next frontier in data analytics\r\nIntroduction to Data Analysis for Auditors and Accountants\r\nRethinking the audit\r\nAudit at a Crossroads\r\nMateriais online diversos\r\nListo a seguir alguns materiais que estão disponíveis na internet:\r\nAudit Data Analytics - AICPA\r\nAudit Analytics - An innovative course at Rutgers\r\nAUDIT QUALITY THEMATIC REVIEW: THE USE OF DATA ANALYTICS IN THE AUDIT OF FINANCIAL STATEMENTS\r\nAudit Data Standards Python Example\r\nAudit Solution in R- Case Study: Analysis of General Ledger\r\nAudit Solution in R- Case Study: Analysis of Sales/AR\r\nAnalytical Procedures in R - Audit Data Analytics (ADA) Use Case\r\nraudit\r\nAudit Data Analytics (ADA) - stewartli\r\nData mining your general ledger with Excel\r\nAuditinsight\r\nAudit Analytics: Data Science for the Accounting Profession\r\nAudit Analytics with R - Jonathan Lin\r\nAudit Analytics: Data Science for the Accounting Profession\r\nJon Lin - repositório no GitHub\r\nCaso o leitor tenha conhecimento de algum material não elencado neste post, pode me encaminhar. Vou atualizando o post à medida que for tomando conhecimento de mais materiais.\r\nEspero que gostem.\r\nBoa leitura!\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2021-01-31T21:58:27-03:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-01-23-sobre-bigodes-e-violinos/",
    "title": "Sobre Bigodes e Violinos",
    "description": "Algumas considerações sobre alguns gráficos apresentados no capítulo Foundations of Audit Analystics do livro [Audit Analytics](https://www.springer.com/gp/book/9783030490904) do J. C. Westland.",
    "author": [
      {
        "name": "Marcos F. Silva",
        "url": {}
      }
    ],
    "date": "2021-01-24",
    "categories": [
      "Livro Audit Analytics"
    ],
    "contents": "\r\n\r\nContents\r\nConsiderações iniciais\r\nGráficos apresentados no capítulo\r\n\r\nConsiderações iniciais\r\nEm linhas gerais o capítulo trata da exploração grafica de variáveis em um conjunto de dados, dos tipos de variáveis e comenta sobre as estruturas de dados existentes no R (vetores, matrizes, arrays, data frames, listas e fatores) e comenta rapidamente sobre a importância de outras estruturas de dados importantes em contabilidade como as séries temporais, os dados geolocalizados e os grafos.\r\nUma novidade pra mim foi o pacote plotluck que eu não conhecia. O pacote se propõe a apresentar a melhor visualização dos dados com base em suas características.\r\nO livro possui um pacote associado chamado auditanalytics e pode ser instalado a partir do repositório do livo no GitHub onde estão disponíveis os dados utilizados, bem como notebooks com resumos dos capítulos do livro.\r\nO resumo do capítulo 2 está contido no arquivo ch_2_statistics_analytics.Rmd.\r\nA instalação do pacote pode ser feita da seguinte forma:\r\n\r\n\r\n# install.packages(\"devtools\")\r\ndevtools::install_github(\"westland/auditanalytics\")\r\n\r\n\r\n\r\nOs dados utilizados estão armazenados em arquivos csv no próprio pacote e nesse aspecto acho que um ponto de melhoria seria disponibilizá-los no formato .RData com a correspondente documentação como usualmente ocorre nos pacotes do R.\r\nA falta de documentação dos dados, tanto no livro como no repositório e no pacote é uma falha importante visto que uma boa análise de dados pressupõe um bom conhecimento dos mesmos.\r\nA disponibilização dos dados em arquivos csv torna a importação um pouco mais trabalhosa.\r\nGráficos apresentados no capítulo\r\nA motivação para eu escrever este post foi a percepção de que alguns dos gráficos apresentados no capítulo não me pareceram uma boa escolha ou talvez eu não tenha compreendido corretamente a proposta do autor.\r\nO capítulo apresenta ao leitor quatro tipos de gráficos: histograma, gráfico de violino, boxplot e diagrama de dispersão como formas de explorar os dados, o que me faz chamar a atenção para o fato de que os gráficos a serem utilizados pelo auditor em grande medida dependem do tipo de dado que se queira visualizar e que infelizmente o uso de gráficos pelos auditores como uma ferramenta de exploração é ainda bastante incipiente.\r\nO primeiro gráfico que eu gostaria de comentar consta da página 29 e tem por objetivo, nas palavras do autor:\r\n\r\n“Na figura a seguir estamos interessados em saber se a fraude em cartões de crédito é influenciada pelo valor pago ao auditor. A gente analisa uma variável binária examinando a variação em uma outra variável conforme os valores da mesma estejam associados ao valor 0 ou 1 da variável binária.”\r\n\r\nO gráfico em questão, utilizado com vistas a ilustrar a exploração de variáveis binárias, é o seguinte:\r\n\r\nShow code\r\nlibrary(auditanalytics)\r\nlibrary(ggplot2)\r\nlibrary(dplyr)\r\n\r\n# Importação dos dados\r\nsox_stats <- read.csv(system.file(\"extdata\", \"ch_2_data_types.csv\", package=\"auditanalytics\", mustWork=TRUE))\r\n\r\n# Gráfico\r\nggplot(sox_stats, aes(x=non_audit_fee, y=audit_fee, col=as.factor(card)))+\r\n  geom_violin() +\r\n  labs(col=\"Fraud = 1 (green)\")\r\n\r\n\r\n\r\n\r\nA primeira coisa a comentar é o uso do gráfico de violino, que por ser um gráfico muito pouco conhecido, certamente não seria uma opção para a grande maioria dos auditores.\r\nA ajuda da função geom_violin() diz que “O gráfico de violino é uma representação compacta de uma distribuição contínua. É uma mistura do geom_boxplot() e do geom_density(): o gráfico de violino é um gráfico de densidade ‘espelhado’ representado da mesma forma que um boxplot.”\r\nO “box and whisker plot” (gráfico de caixa e bigodes) ou simplesmente boxplot, é um gráfico que tem por objetivo apresentar a distribuição de uma variável quantitativa por intermédio dos quartis da distribuição e indicação de limites superiores e inferiores denominados “cercas”.\r\nO boxplot e o gráfico de violino tem função semelhante, sendo que o gráfico de violino tem a vantagem de mostrar além da variabilidade dos dados e os quartis a forma da distribuição da variável por intermédio de sua densidade.\r\nA seguir apresento o mesmo conjunto de dados usando um boxplot, um gráfico de densidade e um gráfico de violino para tentar realçar a diferença entre os dois. Os dados são apresentados em cinza para dar uma ideia da localização dos mesmos.\r\n\r\nShow code\r\n# Boxplot\r\nsox_stats %>% \r\n  filter(card %in% c(0, 1)) %>% \r\nggplot(aes(y=audit_fee, x=as.factor(card)))+\r\n  geom_boxplot() +\r\n  geom_jitter(color=\"grey\", width = 0.2)\r\n\r\n\r\nShow code\r\n# Density\r\nsox_stats %>% \r\n  filter(card %in% c(0, 1)) %>% \r\nggplot(aes(y=audit_fee))+\r\n  geom_density(fill=\"lightblue\") +\r\n  facet_wrap(~ as.factor(card)) \r\n\r\n\r\nShow code\r\n# Violino\r\nsox_stats %>% \r\n  filter(card %in% c(0, 1)) %>% \r\nggplot(aes(y=audit_fee, x=as.factor(card)))+\r\n  geom_violin(draw_quantiles = c(0.25, 0.5, 0.75), color=\"blue\") +\r\n  geom_jitter(color=\"grey\", width = 0.2)\r\n\r\n\r\n\r\n\r\nExaminando os três gráficos é possível perceber que o gráfico de violino é um gráfico de densidade refletido, o que lhe dá a simetria observada e é também parecido com um boxplot, mostrando a variabilidade dos dados e os quartis.\r\nOnde existe maior concentração de dados, o gráfico de violino expressa isso na “largura” da curva, ou seja, onde tem maior concentração de dados a curva é mais larga.\r\nVoltando ao gráfico apresentado pelo autor, comentei que o objetivo declarado desse gráfico seria avaliar se a fraude em cartões de crédito é influencidada pelo valor pago aos auditores contratados.\r\nO gráfico faz uso de 3 variáveis: audit_fee, non_audit_fee e card e como já disse a base de dados não está comentada, não possuindo informações sobre o significado de cada variável e a estrutura geral dos dados. Assim, será necessário deduzir algumas coisas, o que não é o que se deve fazer na prática. O auditor deve buscar compreender com a maior clareza possível o significado de cada variável e suas particularidades para que possa ter condições de identificar situações que fujam da normalidade.\r\nAparentemente a variável card indica se a observação refere-se à fraude ou não. As outras variáveis indicam o valor pago aos auditores em razão de serviços contratados de auditoria e serviços não relacionados a auditoria.\r\nA primeira coisa que não fica clara no gráfico apresentado é o uso da variável non_audit_fee, uma variável quantitativa contínua, no eixo dos x. Considerando que o objetivo de um gráfico de violino é representar a distribuição da variável no eixo y, que deve ser quantitativa, a variável non_audit_fee não traz informação adicional para o gráfico.\r\nO mesmo problema ocorre com o gráfico apresentado na página 30, e que reproduzo a seguir utilizando o código apresentado no livro:\r\n\r\nShow code\r\nlibrary(tidyr)\r\n\r\nsox_stats$card <- as.integer(sox_stats$card)\r\n\r\nsox_stats1 <- gather(sox_stats,\r\n                     key=\"metric\",\r\n                     value = value,\r\n                     effective_303,\r\n                     mat_weak_303,\r\n                     sig_def_303,\r\n                     effective_404,\r\n                     auditor_agrees_303)\r\n\r\nggplot(sox_stats1, aes(x=non_audit_fee, y=audit_fee, col=metric)) +\r\n  geom_violin() +\r\n  scale_x_continuous(trans = \"log2\") +\r\n  scale_y_continuous(trans = \"log2\")\r\n\r\n\r\n\r\n\r\nO gráfico mostra os “violinos” igualmente espaçados e mostrando a mesma distribuição para a variável audit_fee para todos os valores da variável metric.\r\nNovamente aqui a variável non_audit_fee parece não ter qualquer influência no gráfico. Chama a atenção também o fato dos “violinos” serem todos iguais. O fato de não conhecermos em mais detalhes a base de dados dificulta a inspeção em busca de confirmação quanto a correção do resultado apresentado.\r\nO fato é que não é possível extrair maiores informações nem confirmar a exatidão do resultado sem um maior conhecimento dos dados.\r\nTambém os gráficos apresentados nas páginas 31 e 32 não me pareceram uma boa escolha para o propósito desejado.\r\nAqui o objetivo do autor é ilustrar a análise de variáveis ordinais, mais especificamente omissões ou duplicidades em variáveis que possuem valores sequenciais, tais como os números das notas fiscais.\r\nO gráfico a seguir, apresentado pelo autor, tem o objetivo de permitir a identificação visual de faturas duplicadas.\r\n\r\nShow code\r\nlibrary(lubridate)\r\n#library(kableExtra)\r\n\r\n## função para gerar datas aleatórias no ano corrente\r\nrdate <- function(x,\r\n                  min = paste0(format(Sys.Date(), '%Y'), '-01-01'),\r\n                  max = paste0(format(Sys.Date(), '%Y'), '-12-31'),\r\n                  sort = TRUE) {\r\n  dates <- sample(seq(as.Date(min), as.Date(max), by = \"day\"), x, replace = TRUE)\r\n  if (sort == TRUE) {\r\n    sort(dates)\r\n  } else {\r\n    dates\r\n  }\r\n}\r\n\r\n## Cria um data frame com 2 coluna e preenche com os valores 1 a 1000 \r\ninvoice_no <- date <- 1:1000  ## placeholder\r\njournal_ent_no <- cbind.data.frame(invoice_no,date)\r\n\r\n# Sorteia 1000 datas entre 01-01-2021 e 31-12-2021 e ordena\r\ndate <- rdate(1000)\r\n\r\n# Substitui os valores no campo 'data' pelas datas sorteadas\r\njournal_ent_no$date <- date[order(date)]\r\n\r\n# Adiciona duplicidades \r\njournal_ent_no$invoice_no <- seq(1,1000) + rbinom(1000,1,.1) # add some errors\r\n\r\n# Cria um novo data frame com identificação das duplicidades.\r\nduplicates <- duplicated(journal_ent_no$invoice_no)\r\nraw <- seq(1,1000)\r\njournal_dups <- cbind.data.frame(raw,duplicates)\r\n\r\n# Faz o gráfico\r\nggplot(journal_dups, aes(x=invoice_no, y=raw, col=duplicates)) + \r\n  geom_point()\r\n\r\n\r\n\r\n\r\nComo pode ser visto as duplicidades, em azul, não sobressaem muito. Como o espaço para o gráfico é pequeno os pontos se sobrepõem, dificultando a visualização.\r\nVou mostrar os registros iniciais do conjunto de dados utilizado para fazer esse gráfico:\r\n\r\nShow code\r\nhead(journal_dups, 10)\r\n\r\n\r\n   raw duplicates\r\n1    1      FALSE\r\n2    2      FALSE\r\n3    3      FALSE\r\n4    4      FALSE\r\n5    5      FALSE\r\n6    6      FALSE\r\n7    7      FALSE\r\n8    8      FALSE\r\n9    9      FALSE\r\n10  10      FALSE\r\n\r\nO conjunto de dados consiste em uma coluna indicando a numeração sequencial de 1 a 1000 e outra indicando se o número está duplicado na base ou não. Esta base de dados é derivada do que seria a base “original” que apresento a seguir:\r\n\r\nShow code\r\nhead(journal_ent_no, 10)\r\n\r\n\r\n   invoice_no       date\r\n1           1 2021-01-01\r\n2           2 2021-01-01\r\n3           3 2021-01-04\r\n4           4 2021-01-04\r\n5           5 2021-01-04\r\n6           6 2021-01-04\r\n7           7 2021-01-04\r\n8           8 2021-01-05\r\n9           9 2021-01-05\r\n10         10 2021-01-05\r\n\r\nA base de dados possui o número sequencial (invoice_no) e a data de emissão (date). Será que tem uma forma melhor de “visualizar” as duplicidades?\r\nVou apresentar aqui minha proposta:\r\n\r\nShow code\r\nggplot(journal_dups) + \r\n  geom_vline(xintercept = invoice_no,\r\n             color=ifelse(duplicates, \"blue\", \"white\"))+\r\n  labs(x=\"Numeração Sequencial\")\r\n\r\n\r\n\r\n\r\nAs linhas em azul indicam as faturas duplicadas. Podemos ver que a distribuição das duplicidades não aparenta ter um padrão definido.\r\nNa minha opinião a visualização das duplicidades ficou um pouco melhor. Naturalmente que quanto maior a quantidade de dados mais difícil ficará a visualização, principalmente se a mesma referir-se a visualizar os dados inidividualmente, como é o caso apresentado pelo autor.\r\nÉ claro que com um simples filtro é possível obter exatamente os números das faturas duplicadas, mas seria difícil perceber qualquer padrão nos dados caso eles existissem.\r\nO gráfico na página 32 é muito parecido mas busca identificar faturas omitidas. Acredito que a mesma solução pode ser usada na visualização.\r\nBem, por ora é tudo. Espero que tenham gostado.\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-01-23-sobre-bigodes-e-violinos/sobre-bigodes-e-violinos_files/figure-html5/unnamed-chunk-2-1.png",
    "last_modified": "2021-01-24T23:57:17-03:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  }
]
